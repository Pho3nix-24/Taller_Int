{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Paqueteo mínimo y compatible (no fijes gradio-client a mano)\n",
        "# Instalar plotly\n",
        "!pip install gradio\n",
        "!pip install gradio plotly -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nCjziHjISsYq",
        "outputId": "f71d336c-c7ae-4136-ec3c-72ba3ac2a052"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.119.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.3)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.1)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd\n",
        "rng = np.random.default_rng(42)\n",
        "\n",
        "n = 12000\n",
        "carreras = [\n",
        "    \"Ingeniería de Sistemas\",\"Administración de Empresas\",\"Psicología\",\n",
        "    \"Derecho\",\"Educación Primaria\",\"Contabilidad y Finanzas\",\n",
        "    \"Arquitectura\",\"Ciencias de la Comunicación\",\"Medicina Humana\",\n",
        "    \"Ingeniería Industrial\"\n",
        "]\n",
        "\n",
        "# Probabilidades que SUMAN 1.0 exactamente\n",
        "p = np.array([0.105, 0.105, 0.105, 0.105, 0.10, 0.10, 0.095, 0.095, 0.095, 0.095])\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"alumno_id\": np.arange(1, n+1),\n",
        "    \"estructuraalumno\": rng.choice(carreras, size=n, p=p),\n",
        "    \"semestre\": rng.integers(1, 12, size=n),\n",
        "})\n",
        "\n",
        "df[\"creditosmatriculado\"] = rng.choice([12,14,16,18,20,22,24,26,28,30],\n",
        "                                       size=n, p=[.08,.09,.12,.16,.16,.14,.10,.07,.05,.03])\n",
        "df[\"cursosmatriculados\"] = np.clip((df[\"creditosmatriculado\"]/4 + rng.normal(0,1,size=n))\n",
        "                                   .round().astype(int), 3, 10)\n",
        "\n",
        "# Tasa base por carrera (promedios razonables)\n",
        "base_aprob = df[\"estructuraalumno\"].map({\n",
        "    \"Psicología\":0.77,\"Derecho\":0.76,\"Educación Primaria\":0.755,\"Contabilidad y Finanzas\":0.75,\n",
        "    \"Arquitectura\":0.745,\"Ciencias de la Comunicación\":0.748,\"Medicina Humana\":0.74,\n",
        "    \"Ingeniería Industrial\":0.742,\"Ingeniería de Sistemas\":0.735,\"Administración de Empresas\":0.736\n",
        "}).values\n",
        "\n",
        "# Ajuste por semestre (ligero)\n",
        "adj_sem = 0.01*(df[\"semestre\"]>=7).astype(float) - 0.015*(df[\"semestre\"]<=2).astype(float)\n",
        "\n",
        "# Probabilidad base (antes de inyectar anomalías)\n",
        "p_apr = np.clip(base_aprob + adj_sem + rng.normal(0,0.03,size=n), 0.55, 0.95)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# === ANOMALÍAS SINTÉTICAS (para que salten en tus análisis)\n",
        "# ----------------------------------------------------------\n",
        "marca = np.array([\"\"]*n, dtype=object)\n",
        "\n",
        "# 1) Desplazamientos a NIVEL CARRERA (afecta a TODA la carrera)\n",
        "#    - Ingeniería de Sistemas: caída fuerte (-0.06)  -> debería quedar outlier por abajo\n",
        "#    - Psicología: subida fuerte (+0.05)              -> outlier por arriba\n",
        "shift_carrera = {\n",
        "    \"Ingeniería de Sistemas\": -0.06,\n",
        "    \"Psicología\": +0.05\n",
        "}\n",
        "shift_vec = df[\"estructuraalumno\"].map(shift_carrera).fillna(0.0).values\n",
        "p_apr = p_apr + shift_vec\n",
        "marca[shift_vec != 0.0] = np.where(shift_vec[shift_vec != 0.0] > 0, \"boost_carrera\", \"drop_carrera\")\n",
        "\n",
        "# 2) Choque por COHORTE local:\n",
        "#    Medicina Humana en semestre 1 y 2: -0.10 adicional (simula plan de estudios difícil)\n",
        "mask_mh = (df[\"estructuraalumno\"]==\"Medicina Humana\") & (df[\"semestre\"]<=2)\n",
        "p_apr[mask_mh] -= 0.10\n",
        "marca[mask_mh] = np.where(marca[mask_mh] == \"\", \"choque_mh_s1s2\", marca[mask_mh])\n",
        "\n",
        "# 3) “Grupo problema” en Ingeniería Industrial: 30% de sus alumnos bajan -0.08\n",
        "mask_ind = (df[\"estructuraalumno\"]==\"Ingeniería Industrial\")\n",
        "idx_ind = np.where(mask_ind)[0]\n",
        "pick = rng.choice(idx_ind, size=int(0.30*len(idx_ind)), replace=False)\n",
        "p_apr[pick] -= 0.08\n",
        "marca[pick] = np.where(marca[pick] == \"\", \"grupo_bajo_industrial\", marca[pick])\n",
        "\n",
        "# 4) “Grupo excelencia” en Contabilidad y Finanzas: 25% suben +0.07\n",
        "mask_cf = (df[\"estructuraalumno\"]==\"Contabilidad y Finanzas\")\n",
        "idx_cf = np.where(mask_cf)[0]\n",
        "pick_cf = rng.choice(idx_cf, size=int(0.25*len(idx_cf)), replace=False)\n",
        "p_apr[pick_cf] += 0.07\n",
        "marca[pick_cf] = np.where(marca[pick_cf] == \"\", \"grupo_alto_conta\", marca[pick_cf])\n",
        "\n",
        "# Reclip final de probabilidades\n",
        "p_apr = np.clip(p_apr, 0.40, 0.98)\n",
        "\n",
        "# ---------------------------------\n",
        "# Generación de resultados académicos\n",
        "# ---------------------------------\n",
        "df[\"cursosaprobados\"] = [rng.binomial(m, p) for m,p in zip(df[\"cursosmatriculados\"], p_apr)]\n",
        "df[\"creditosaprobadostotal\"] = (df[\"cursosaprobados\"]*4 + rng.integers(-2,3,size=n)).clip(0)\n",
        "\n",
        "# Notas relacionadas pero con ruido (coherentes con p_apr)\n",
        "df[\"promediosemestre\"] = np.clip(rng.normal(12.2 + 5*(p_apr-0.7), 1.4, size=n), 8, 20).round(2)\n",
        "df[\"promedioponderado\"] = (0.6*df[\"promediosemestre\"] + 0.4*np.clip(\n",
        "    rng.normal(df[\"promediosemestre\"],1.0,size=n),8,20)).round(2)\n",
        "\n",
        "# Marca de anomalía para auditoría (útil para validar resultados)\n",
        "df[\"marca_anomalia\"] = marca\n",
        "\n",
        "csv_path = \"/content/estudiantes_univ.csv\"\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(\"CSV creado en:\", csv_path, \"| filas:\", len(df))\n",
        "print(df[\"marca_anomalia\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xems4boRdJW0",
        "outputId": "32a14227-0908-443c-ee97-2f8d23cdf153"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV creado en: /content/estudiantes_univ.csv | filas: 12000\n",
            "marca_anomalia\n",
            "                         8652\n",
            "boost_carrera            1268\n",
            "drop_carrera             1228\n",
            "grupo_bajo_industrial     336\n",
            "grupo_alto_conta          302\n",
            "choque_mh_s1s2            214\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# IMPORTS Y FUNCIONES ORIGINALES (con pequeñas protecciones)\n",
        "# =========================================================\n",
        "import io, os, gc\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "def cargar_y_limpiar(file_obj) -> pd.DataFrame:\n",
        "    df = pd.read_csv(file_obj if isinstance(file_obj, str) else file_obj.name)\n",
        "    # a numérico seguro\n",
        "    for c in [\"cursosmatriculados\",\"cursosaprobados\",\"creditosmatriculado\",\"creditosaprobadostotal\",\n",
        "              \"promediosemestre\",\"promedioponderado\",\"semestre\"]:\n",
        "        if c in df.columns:\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "    # reglas mínimas\n",
        "    df = df.dropna(subset=[\"estructuraalumno\",\"cursosmatriculados\",\"cursosaprobados\"]).copy()\n",
        "    df = df[df[\"cursosmatriculados\"] > 0]\n",
        "    return df\n",
        "\n",
        "def _texto_semestres(df: pd.DataFrame) -> str:\n",
        "    if \"semestre\" in df.columns and df[\"semestre\"].notna().any():\n",
        "        return f\"{int(df['semestre'].min())} – {int(df['semestre'].max())}\"\n",
        "    return \"N/D\"\n",
        "\n",
        "def resumen_texto(df: pd.DataFrame) -> str:\n",
        "    tasa = (df[\"cursosaprobados\"]/df[\"cursosmatriculados\"]).mean()\n",
        "    return (\n",
        "        f\"**Registros:** {len(df):,}\\n\\n\"\n",
        "        f\"**Carreras:** {df['estructuraalumno'].nunique()}\\n\\n\"\n",
        "        f\"**Tasa de aprobación global:** {tasa:.2%}\\n\\n\"\n",
        "        f\"**Semestres (min–max):** {_texto_semestres(df)}\"\n",
        "    )\n",
        "\n",
        "def top8_bar(df: pd.DataFrame) -> str:\n",
        "    aux = df.copy()\n",
        "    aux[\"tasa\"] = aux[\"cursosaprobados\"]/aux[\"cursosmatriculados\"]\n",
        "    tasa_carrera = (\n",
        "        aux.groupby(\"estructuraalumno\")[\"tasa\"]\n",
        "           .mean()\n",
        "           .sort_values(ascending=False)\n",
        "           .head(8)\n",
        "           .reset_index()\n",
        "    )\n",
        "    tasa_carrera = tasa_carrera[tasa_carrera[\"tasa\"].notna()]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "    sns.barplot(data=tasa_carrera, y=\"estructuraalumno\", x=\"tasa\", ax=ax, palette=\"viridis\")\n",
        "    ax.set_title(\"Top 8 carreras por tasa de aprobación promedio\")\n",
        "    ax.set_xlabel(\"Tasa de aprobación\"); ax.set_ylabel(\"Carrera\")\n",
        "    for i, v in enumerate(tasa_carrera[\"tasa\"]):\n",
        "        ax.text(v, i, f\"{v:.2%}\", va=\"center\", ha=\"left\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    out = \"/content/top8_tasa.png\"\n",
        "    fig.savefig(out, dpi=140, bbox_inches=\"tight\"); plt.close(fig)\n",
        "    return out\n",
        "\n",
        "def matriz_indicadores(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = (\n",
        "        df.assign(tasa=lambda d: d[\"cursosaprobados\"]/d[\"cursosmatriculados\"])\n",
        "          .groupby(\"estructuraalumno\")\n",
        "          .agg(\n",
        "              n=(\"alumno_id\",\"count\") if \"alumno_id\" in df.columns else (\"estructuraalumno\",\"count\"),\n",
        "              tasa_prom=(\"tasa\",\"mean\"),\n",
        "              cursos_m=(\"cursosmatriculados\",\"mean\"),\n",
        "              prom_sem=(\"promediosemestre\",\"mean\") if \"promediosemestre\" in df.columns else (\"cursosmatriculados\",\"mean\"),\n",
        "              prom_pond=(\"promedioponderado\",\"mean\") if \"promedioponderado\" in df.columns else (\"cursosmatriculados\",\"mean\"),\n",
        "          )\n",
        "          .sort_values(\"tasa_prom\", ascending=False)\n",
        "    )\n",
        "    return out.round({\"tasa_prom\":4,\"cursos_m\":2,\"prom_sem\":2,\"prom_pond\":2}).reset_index()\n",
        "\n",
        "def detectar_outliers_simple(tab: pd.DataFrame,\n",
        "                             method: str = \"iqr\",\n",
        "                             k_iqr: float = 1.5,\n",
        "                             z_thr: float = 2.0,\n",
        "                             mad_thr: float = 3.5,\n",
        "                             min_n: int = 50) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Marca anomalias en 'tasa_prom' por carrera.\n",
        "    - method: \"iqr\" | \"z\" | \"mad\"\n",
        "    - min_n: mínimo de registros por carrera para ser evaluada\n",
        "    \"\"\"\n",
        "    out = tab.copy()\n",
        "    out[\"anomalia\"] = \"\"\n",
        "    # filtra carreras con suficiente tamaño muestral si existe 'n'\n",
        "    mask_eval = out[\"n\"] >= min_n if \"n\" in out.columns else np.ones(len(out), dtype=bool)\n",
        "    s = pd.to_numeric(out.loc[mask_eval, \"tasa_prom\"], errors=\"coerce\").dropna()\n",
        "\n",
        "    # si no hay datos suficientes o no hay variación, no marcamos nada\n",
        "    if len(s) < 4 or s.nunique() < 2:\n",
        "        return out\n",
        "\n",
        "    if method.lower() == \"iqr\":\n",
        "        q1, q3 = s.quantile([0.25, 0.75])\n",
        "        iqr = q3 - q1\n",
        "        # si iqr≈0, cae a z-score para evitar “todo vacío”\n",
        "        if iqr <= 1e-9:\n",
        "            m, sd = s.mean(), s.std(ddof=1)\n",
        "            if sd <= 1e-9:  # sin variación\n",
        "                return out\n",
        "            flags = (np.abs((out[\"tasa_prom\"] - m) / sd) > z_thr) & mask_eval\n",
        "        else:\n",
        "            low, high = q1 - k_iqr * iqr, q3 + k_iqr * iqr\n",
        "            flags = ((out[\"tasa_prom\"] < low) | (out[\"tasa_prom\"] > high)) & mask_eval\n",
        "\n",
        "    elif method.lower() == \"z\":\n",
        "        m, sd = s.mean(), s.std(ddof=1)\n",
        "        if sd <= 1e-9:\n",
        "            return out\n",
        "        flags = (np.abs((out[\"tasa_prom\"] - m) / sd) > z_thr) & mask_eval\n",
        "\n",
        "    else:  # \"mad\" robusto\n",
        "        med = s.median()\n",
        "        mad = (np.abs(s - med)).median()\n",
        "        if mad <= 1e-9:\n",
        "            return out\n",
        "        z_mad = 0.6745 * (out[\"tasa_prom\"] - med) / mad\n",
        "        flags = (np.abs(z_mad) > mad_thr) & mask_eval\n",
        "\n",
        "    out.loc[flags, \"anomalia\"] = \"⚠️\"\n",
        "    return out\n",
        "\n",
        "def pipeline(file_obj):\n",
        "    df = cargar_y_limpiar(file_obj)\n",
        "    txt = resumen_texto(df)\n",
        "    img = top8_bar(df)\n",
        "    tabla = detectar_outliers_simple(matriz_indicadores(df))\n",
        "    gc.collect()\n",
        "    return txt, img, tabla\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# VISUALIZACIONES EXTRA (compatibles con tu flujo)\n",
        "# =========================================================\n",
        "\n",
        "def _filtrar_base(df, carreras_sel=None, sem_min=1, sem_max=12):\n",
        "    g = df.copy()\n",
        "    for c in [\"cursosaprobados\",\"cursosmatriculados\",\"creditosmatriculado\",\"creditosaprobadostotal\",\"semestre\"]:\n",
        "        if c in g.columns:\n",
        "            g[c] = pd.to_numeric(g[c], errors=\"coerce\")\n",
        "    g = g.dropna(subset=[\"cursosaprobados\",\"cursosmatriculados\"])\n",
        "    g = g[g[\"cursosmatriculados\"] > 0]\n",
        "    if \"semestre\" in g.columns:\n",
        "        smin = int(min(sem_min, sem_max)); smax = int(max(sem_min, sem_max))\n",
        "        g = g[(g[\"semestre\"] >= smin) & (g[\"semestre\"] <= smax)]\n",
        "    if carreras_sel:\n",
        "        g = g[g[\"estructuraalumno\"].astype(str).isin(carreras_sel)]\n",
        "    g[\"tasa\"] = np.divide(g[\"cursosaprobados\"], g[\"cursosmatriculados\"], where=g[\"cursosmatriculados\"]>0)\n",
        "    return g\n",
        "\n",
        "def _msg_fig(texto: str, path=\"/content/viz_msg.png\"):\n",
        "    fig, ax = plt.subplots(figsize=(10,2.8))\n",
        "    ax.axis(\"off\")\n",
        "    ax.text(0.5, 0.5, texto, ha=\"center\", va=\"center\", fontsize=14)\n",
        "    fig.savefig(path, dpi=140, bbox_inches=\"tight\"); plt.close(fig)\n",
        "    return path\n",
        "\n",
        "def plot_extra_top_barras(df, topn=8, carreras_sel=None, sem_min=1, sem_max=12):\n",
        "    g = _filtrar_base(df, carreras_sel, sem_min, sem_max)\n",
        "    if g.empty:\n",
        "        return _msg_fig(\"Sin datos para los filtros seleccionados.\", \"/content/extra_topN.png\")\n",
        "    top = (g.groupby(\"estructuraalumno\")[\"tasa\"].mean()\n",
        "             .sort_values(ascending=False).head(int(topn)).reset_index())\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "    sns.barplot(data=top, y=\"estructuraalumno\", x=\"tasa\", ax=ax, palette=\"viridis\")\n",
        "    ax.set_title(f\"Top {len(top)} carreras por tasa de aprobación promedio\")\n",
        "    ax.set_xlabel(\"Tasa de aprobación\"); ax.set_ylabel(\"Carrera\")\n",
        "    for i, v in enumerate(top[\"tasa\"]): ax.text(v, i, f\"{v:.2%}\", va=\"center\", ha=\"left\")\n",
        "    plt.tight_layout()\n",
        "    out = \"/content/extra_topN.png\"\n",
        "    fig.savefig(out, dpi=140, bbox_inches=\"tight\"); plt.close(fig)\n",
        "    return out\n",
        "\n",
        "def plot_extra_histograma(df, feature=\"tasa\", bins=20, carreras_sel=None, sem_min=1, sem_max=12):\n",
        "    g = _filtrar_base(df, carreras_sel, sem_min, sem_max)\n",
        "    if g.empty:\n",
        "        return _msg_fig(\"Sin datos para los filtros seleccionados.\", \"/content/extra_hist.png\")\n",
        "    feat = \"tasa\" if feature == \"tasa\" else feature\n",
        "    if feat not in g.columns:\n",
        "        return _msg_fig(f\"No existe la columna '{feature}' en el dataset.\", \"/content/extra_hist.png\")\n",
        "    fig, ax = plt.subplots(figsize=(12,5))\n",
        "    sns.histplot(g[feat].dropna(), bins=int(bins), ax=ax)\n",
        "    ax.set_title(f\"Histograma de {feat}\")\n",
        "    ax.set_xlabel(feat); ax.set_ylabel(\"Frecuencia\")\n",
        "    plt.tight_layout()\n",
        "    out = \"/content/extra_hist.png\"\n",
        "    fig.savefig(out, dpi=140, bbox_inches=\"tight\"); plt.close(fig)\n",
        "    return out\n",
        "\n",
        "def plot_extra_scatter(df, sample=5000, carreras_sel=None, sem_min=1, sem_max=12):\n",
        "    g = _filtrar_base(df, carreras_sel, sem_min, sem_max)\n",
        "    if g.empty:\n",
        "        return _msg_fig(\"Sin datos para los filtros seleccionados.\", \"/content/extra_scatter.png\")\n",
        "    # eje X: preferir creditosmatriculado, si no existe usar cursosmatriculados\n",
        "    xcol = \"creditosmatriculado\" if \"creditosmatriculado\" in g.columns else \"cursosmatriculados\"\n",
        "    if len(g) > sample:\n",
        "        g = g.sample(int(sample), random_state=42)\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "    ax.scatter(g[xcol], g[\"tasa\"], alpha=0.25, s=10)\n",
        "    ax.set_title(f\"Dispersión: {xcol} vs tasa de aprobación (muestra)\")\n",
        "    ax.set_xlabel(xcol); ax.set_ylabel(\"Tasa de aprobación\")\n",
        "    ax.grid(True, alpha=0.25)\n",
        "    plt.tight_layout()\n",
        "    out = \"/content/extra_scatter.png\"\n",
        "    fig.savefig(out, dpi=140, bbox_inches=\"tight\"); plt.close(fig)\n",
        "    return out\n",
        "\n",
        "def plot_extra_heatmap(df, carreras_sel=None, sem_min=1, sem_max=12):\n",
        "    g = _filtrar_base(df, carreras_sel, sem_min, sem_max)\n",
        "    if g.empty:\n",
        "        return _msg_fig(\"Sin datos para los filtros seleccionados.\", \"/content/extra_heatmap.png\")\n",
        "    if \"creditosmatriculado\" not in g.columns:\n",
        "        return _msg_fig(\"No hay 'creditosmatriculado' para el heatmap.\", \"/content/extra_heatmap.png\")\n",
        "    bins = [0, 9, 12, 15, 18, 21, 24, 27, np.inf]\n",
        "    labels = [\"≤9\",\"10–12\",\"13–15\",\"16–18\",\"19–21\",\"22–24\",\"25–27\",\"≥28\"]\n",
        "    g[\"_bin_cred\"] = pd.cut(pd.to_numeric(g[\"creditosmatriculado\"], errors=\"coerce\"),\n",
        "                            bins=bins, labels=labels, include_lowest=True)\n",
        "    tab = (g.groupby([\"estructuraalumno\",\"_bin_cred\"], observed=False)[\"tasa\"]\n",
        "             .mean().unstack().reindex(columns=labels))\n",
        "    if tab.notna().sum().sum() == 0:\n",
        "        return _msg_fig(\"No hay promedios válidos para el heatmap.\", \"/content/extra_heatmap.png\")\n",
        "    fig, ax = plt.subplots(figsize=(14,8))\n",
        "    sns.heatmap(tab, annot=True, fmt=\".2f\", cmap=\"viridis\",\n",
        "                linewidths=.5, cbar_kws={'label':'Tasa prom.'}, vmin=0, vmax=1, ax=ax)\n",
        "    ax.set_title(\"Tasa por carrera × tramo de créditos\")\n",
        "    ax.set_xlabel(\"Créditos matriculados\"); ax.set_ylabel(\"Carrera\")\n",
        "    plt.tight_layout()\n",
        "    out = \"/content/extra_heatmap.png\"\n",
        "    fig.savefig(out, dpi=140, bbox_inches=\"tight\"); plt.close(fig)\n",
        "    return out\n",
        "\n",
        "def run_viz_extra(file_obj,\n",
        "                  chart_kind=\"Top-N (barras)\",\n",
        "                  topn=8, bins=20, sample_scatter=5000,\n",
        "                  carreras_sel=None, sem_min=1, sem_max=12):\n",
        "    \"\"\"\n",
        "    chart_kind ∈ {\"Top-N (barras)\", \"Histograma (tasa)\", \"Dispersión\", \"Heatmap\"}\n",
        "    Devuelve el path del PNG generado (si no hay datos, devuelve PNG con mensaje).\n",
        "    \"\"\"\n",
        "    df = cargar_y_limpiar(file_obj)\n",
        "    if chart_kind == \"Top-N (barras)\":\n",
        "        return plot_extra_top_barras(df, topn=topn, carreras_sel=carreras_sel,\n",
        "                                     sem_min=sem_min, sem_max=sem_max)\n",
        "    elif chart_kind == \"Histograma (tasa)\":\n",
        "        return plot_extra_histograma(df, feature=\"tasa\", bins=bins, carreras_sel=carreras_sel,\n",
        "                                     sem_min=sem_min, sem_max=sem_max)\n",
        "    elif chart_kind.startswith(\"Dispersión\"):\n",
        "        return plot_extra_scatter(df, sample=sample_scatter, carreras_sel=carreras_sel,\n",
        "                                  sem_min=sem_min, sem_max=sem_max)\n",
        "    else:\n",
        "        return plot_extra_heatmap(df, carreras_sel=carreras_sel, sem_min=sem_min, sem_max=sem_max)"
      ],
      "metadata": {
        "id": "mcCqE2YndJaL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "\n",
        "# ---- helpers para poblar opciones dinámicas desde el CSV ----\n",
        "def _leer_head(file_obj, max_rows=200_000):\n",
        "    df = pd.read_csv(file_obj.name if hasattr(file_obj, \"name\") else file_obj,\n",
        "                     nrows=max_rows)\n",
        "    return df\n",
        "\n",
        "def get_meta_from_file(file_obj):\n",
        "    \"\"\"Devuelve lista de carreras únicas y rango de semestres (min, max).\"\"\"\n",
        "    try:\n",
        "        df = _leer_head(file_obj)\n",
        "        carreras = sorted(map(str, df[\"estructuraalumno\"].dropna().astype(str).unique())) \\\n",
        "                   if \"estructuraalumno\" in df.columns else []\n",
        "        if \"semestre\" in df.columns and pd.to_numeric(df[\"semestre\"], errors=\"coerce\").notna().any():\n",
        "            sem_min = int(pd.to_numeric(df[\"semestre\"], errors=\"coerce\").min())\n",
        "            sem_max = int(pd.to_numeric(df[\"semestre\"], errors=\"coerce\").max())\n",
        "        else:\n",
        "            sem_min, sem_max = 1, 12\n",
        "        return carreras, sem_min, sem_max\n",
        "    except Exception:\n",
        "        return [], 1, 12\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"Análisis de Tasa de Estudiantes\") as app:\n",
        "    gr.Markdown(\n",
        "        \"# Data Mining para patrones anómalos en la tasa de estudiantes universitarios\\n\"\n",
        "        \"Carga tu CSV y explora indicadores, **top 8** por tasa y visualizaciones extra.\"\n",
        "    )\n",
        "\n",
        "    # ========= Entrada común =========\n",
        "    with gr.Row():\n",
        "        inp = gr.File(label=\"Sube tu CSV (o usa el que te di)\", file_types=[\".csv\"])\n",
        "\n",
        "    # guardamos metadatos del archivo para poblar controles dinámicos\n",
        "    carreras_state = gr.State([])\n",
        "    sem_min_state  = gr.State(1)\n",
        "    sem_max_state  = gr.State(12)\n",
        "\n",
        "    # al subir archivo, calculamos opciones de carreras y rango de semestres\n",
        "    def on_file(file_obj):\n",
        "        carreras, a, b = get_meta_from_file(file_obj)\n",
        "        return carreras, a, b, gr.update(choices=carreras)\n",
        "    carreras_dd_for_update = gr.CheckboxGroup(choices=[], visible=False)  # dummy receptor\n",
        "\n",
        "    inp.change(\n",
        "        on_file,\n",
        "        inputs=inp,\n",
        "        outputs=[carreras_state, sem_min_state, sem_max_state, carreras_dd_for_update],\n",
        "        queue=False,\n",
        "    )\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # ========= TAB 1: flujo original =========\n",
        "        with gr.Tab(\"Análisis base\"):\n",
        "            with gr.Row():\n",
        "                btn = gr.Button(\"Analizar\", variant=\"primary\")\n",
        "            with gr.Row():\n",
        "                out_txt = gr.Markdown(label=\"Resumen\")\n",
        "            with gr.Row():\n",
        "                out_img = gr.Image(label=\"Top 8 por tasa\",\n",
        "                                   show_download_button=True, type=\"filepath\")\n",
        "            with gr.Row():\n",
        "                out_tab = gr.Dataframe(\n",
        "                    label=\"Indicadores por carrera (con flag de anormalidad)\",\n",
        "                    interactive=False, wrap=True\n",
        "                )\n",
        "\n",
        "            btn.click(pipeline, inputs=inp, outputs=[out_txt, out_img, out_tab])\n",
        "\n",
        "        # ========= TAB 2: visualizaciones extra =========\n",
        "        with gr.Tab(\"Visualizaciones extra\"):\n",
        "            gr.Markdown(\"Elige el tipo de gráfico y los filtros.\")\n",
        "\n",
        "            with gr.Row():\n",
        "                chart_kind = gr.Radio(\n",
        "                    [\"Top-N (barras)\", \"Histograma (tasa)\", \"Dispersión\", \"Heatmap\"],\n",
        "                    value=\"Top-N (barras)\", label=\"Tipo de gráfico\"\n",
        "                )\n",
        "                topn  = gr.Slider(2, 20, value=8, step=1, label=\"Top-N (para barras)\")\n",
        "                bins  = gr.Slider(5, 60, value=20, step=1, label=\"Bins (para histograma)\")\n",
        "                samp  = gr.Slider(1000, 30000, value=5000, step=500,\n",
        "                                  label=\"Muestra (para dispersión)\")\n",
        "\n",
        "            with gr.Row():\n",
        "                carreras_sel = gr.CheckboxGroup(\n",
        "                    choices=[], label=\"Filtrar carreras (opcional)\"\n",
        "                )\n",
        "                sem_min = gr.Slider(1, 20, value=1, step=1, label=\"Semestre mínimo\")\n",
        "                sem_max = gr.Slider(1, 20, value=12, step=1, label=\"Semestre máximo\")\n",
        "\n",
        "            # cuando subes el archivo, también actualizamos estos controles visibles\n",
        "            def fill_controls(file_obj):\n",
        "                carreras, a, b = get_meta_from_file(file_obj)\n",
        "                return (gr.update(choices=carreras),\n",
        "                        gr.update(value=a),\n",
        "                        gr.update(value=b))\n",
        "            inp.change(fill_controls, inputs=inp,\n",
        "                       outputs=[carreras_sel, sem_min, sem_max], queue=False)\n",
        "\n",
        "            gen = gr.Button(\"Generar gráfico\", variant=\"secondary\")\n",
        "            viz_img = gr.Image(label=\"Visualización\", show_download_button=True, type=\"filepath\")\n",
        "\n",
        "            def _run_viz(file_obj, kind, n, bns, sample, carreras_list, smin, smax):\n",
        "                carreras_list = carreras_list or None  # None si lista vacía\n",
        "                return run_viz_extra(\n",
        "                    file_obj,\n",
        "                    chart_kind=kind,\n",
        "                    topn=int(n),\n",
        "                    bins=int(bns),\n",
        "                    sample_scatter=int(sample),\n",
        "                    carreras_sel=carreras_list,\n",
        "                    sem_min=int(min(smin, smax)),\n",
        "                    sem_max=int(max(smin, smax)),\n",
        "                )\n",
        "\n",
        "            gen.click(\n",
        "                _run_viz,\n",
        "                inputs=[inp, chart_kind, topn, bins, samp, carreras_sel, sem_min, sem_max],\n",
        "                outputs=viz_img\n",
        "            )\n",
        "\n",
        "    # En Colab usa share=True; show_api=False para UI más limpia.\n",
        "    app.launch(share=True, show_api=False, debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "P9KYsd0ldKYc",
        "outputId": "5e0d1abb-a774-480c-c71b-40db95d18231"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://99071d7893b864bfe3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://99071d7893b864bfe3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}